"""
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import os

# T·∫£i tokenizer v√† model
tokenizer = AutoTokenizer.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", use_fast=False)
model = AutoModelForSequenceClassification.from_pretrained("wonrax/phobert-base-vietnamese-sentiment")

import torch.nn.functional as F
from underthesea import word_tokenize

# H√†m d·ª± ƒëo√°n c·∫£m x√∫c
def predict_sentiment(text):
    # T√°ch t·ª´ ti·∫øng Vi·ªát
    text = word_tokenize(text, format="text")

    # Tokenize vƒÉn b·∫£n
    inputs = tokenizer(text, return_tensors="pt", truncation=True)

    # D·ª± ƒëo√°n
    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=1)
        predicted_class = torch.argmax(probs, dim=1).item()

    # G√°n nh√£n
    labels = {0: "Ti√™u c·ª±c", 1: "Trung l·∫≠p", 2: "T√≠ch c·ª±c"}
    return labels[predicted_class]

print(predict_sentiment("S·∫£n ph·∫©m n√†y th·∫≠t tuy·ªát v·ªùi, t√¥i r·∫•t th√≠ch!"))
print(predict_sentiment("D·ªãch v·ª• n√†y th·∫≠t s·ª± t·ªá, t√¥i th·∫•t v·ªçng!"))
print(predict_sentiment("M·ªçi th·ª© ƒë·ªÅu b√¨nh th∆∞·ªùng, kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát."))

"""
"""
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# 1. T·∫£i model v√† tokenizer t·ª´ checkpoint ƒë√£ fine-tuned
checkpoint = "mr4/phobert-base-vi-sentiment-analysis"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

# 2. H√†m d·ª± ƒëo√°n c·∫£m x√∫c v√† x√°c su·∫•t
def predict_sentiment(text):
    inputs = tokenizer([text], padding=True, truncation=True, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
        predicted_label = torch.argmax(probs, dim=1).item()
        label = model.config.id2label[predicted_label]
        return label, probs[0].tolist()  # Tr·∫£ v·ªÅ nh√£n v√† x√°c su·∫•t c·ªßa c√°c l·ªõp

# 3. Nh·∫≠p v√† hi·ªÉn th·ªã k·∫øt qu·∫£ li√™n t·ª•c
if __name__ == "__main__":
    while True:
        text = input("Nh·∫≠p n·ªôi dung c·∫ßn ph√¢n t√≠ch c·∫£m x√∫c (ho·∫∑c 'exit' ƒë·ªÉ tho√°t): ")
        if text.lower() == 'exit':
            print("Tho√°t ch∆∞∆°ng tr√¨nh.")
            break
        result, probabilities = predict_sentiment(text)
        print(f"K·∫øt qu·∫£ d·ª± ƒëo√°n: {result}")
        print(f"X√°c su·∫•t - Negative: {probabilities[0]:.4f}, Positive: {probabilities[1]:.4f}, Neutral: {probabilities[2]:.4f}")
        print("-" * 50)
"""

import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from tqdm import tqdm  # <<== th√™m d√≤ng n√†y

# 1. T·∫£i model v√† tokenizer
checkpoint = "mr4/phobert-base-vi-sentiment-analysis"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

# 2. H√†m d·ª± ƒëo√°n c·∫£m x√∫c
def predict_sentiment(text):
    if not isinstance(text, str):
        text = ""
    inputs = tokenizer([text], padding=True, truncation=True, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
        predicted_label = torch.argmax(probs, dim=1).item()
        label = model.config.id2label[predicted_label]
        return label

# 3. ƒê·ªçc file CSV
df = pd.read_csv(r"G:/My Drive/DATA ANALYST_TH·∫¶Y LONG/GEN 12/LEVEL 2/BU·ªîI 9/SENTIMENT ANALYSIS PROJECT/DATA/mini data.csv")

# 4. Th√™m ti·∫øn tr√¨nh tqdm
tqdm.pandas(desc="üîç ƒêang ph√¢n t√≠ch comment")
df["sentiment"] = df["content"].progress_apply(predict_sentiment)

# 5. Xu·∫•t ra file m·ªõi
df.to_csv(r"G:/My Drive/DATA ANALYST_TH·∫¶Y LONG/GEN 12/LEVEL 2/BU·ªîI 9/SENTIMENT ANALYSIS PROJECT/DATA/mini data with sentiment.csv", index=False)
print("‚úÖ Ph√¢n t√≠ch xong! File ƒë√£ ƒë∆∞·ª£c l∆∞u.")










